---
title: "What Changed Party Identification During the Obama and Trump Presidencies?"
author: "Nic Dias and Lizzie Martin"
date: "May 2, 2021"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

```{r setup, include = F, results = 'hide', warning = F}
# Knitr set-up
knitr::opts_chunk$set(echo = T, fig.width = 8, fig.height = 4)

# Digit rounding set-up
options(scipen = 0, digits = 3)

# Load packages
pacman::p_load(tidyverse, dplyr, ggplot2, ggthemes, data.table, lubridate,
               GGally, RColorBrewer, ggsci, plotROC, usmap, car, psych,
               plotly, ggpubr, vistime, glmnet, leaps, devtools, nlme,
               networkD3, ggalluvial, highcharter, fastDummies, rio, skimr,
               stargazer)
```

# Executive Summary
One cannot understand American politics without understanding party identification. It is an essential source of structure for American public opinion (Campbell et al., 1960). Indeed, while evidence of ideology is difficult to find (Converse, 1964; Kinder & Kalmoe, 2017), those who do exhibit stable beliefs about politics appear to owe that structure to party identification (Freeder et al., 2019). Moreover, voting behavior can increasingly be predicted with a citizen's party identification alone (Bartels, 2000).

## Goal of the Study
While the literature on the effects of party identification is broad, research on when and why party identification *changes* is underdeveloped. What research exists consists of a back-and-forth between two competing accounts: the “social identity” and the “running tally” theories. The former regards party identification as a stable, emotional attachment to a party or the social groups that make up that party (Campbell et al., 1960). The latter considers party identification a continually updated summary of one’s policy preferences and political experiences (Fiorina, 1981). 

In part, little is known about why party identification changes because existing studies have relied on data that render these hypotheses empirically indistinguishable or that have questionable external validity. Panel data provides an opportunity to address both sets of concerns, but party identification is so stable over time that few panels are long enough to capture sufficient variation. In this study, we rely on a 13-year panel spanning the Obama and Trump presidencies that overcomes this problem. We seek to answer two questions: How has party identification evolved in this tumultuous time? And what does this suggest about the nature of party identification?

## Data and Methods
Unlike past work, we do not set out to prove a particular model of party identification. Instead, we use a rich set of data to provide a more robust, empirical basis on which to build future theory. We begin with exploratory data analyses of key variables, such as party identification, attitudes toward the Affordable Care Act (ACA), and retrospective evaluations of the national economy.

We then estimate how each individual panelist changed over time with regard to   time-variant variables (e.g., policy attitudes) by estimating individual, OLS regressions. The estimates from these individual models are then merged with our time-invariant variables (e.g., race) to produce our final dataset. 

We then exhaustively test OLS regressions using all combinations of the 
variables in our final dataset to identify a 'best' model of within-individual
change in party identification. Finally, we use a bootstrapping approach to 
produce reasonable confidence intervals around the estimates in our final model. 

## Findings
Party identification changed considerably over the course of the Obama and Trump presidencies. However, the extent and direction of this change depended on other variables. Our analysis provides more support for the "running tally" model of party identification. In total, six variables related to policy preferences and changeable, political experiences were especially predictive of within-individual change in party identification:

* Attitudes toward the Affordable Care Act in 2008
* Change in attitudes toward the Affordable Care Act over the panel
* Self-reported ideology in 2008
* Change in self-reported ideology over the panel
* Party identification in 2008
* Change in perceptions of the legitimacy of the United States government

# Prior Work on Party Identification
Party identification is at the heart of research on political behavior in U.S. politics, and decades of research on the topic have given way to two central schools of thought on how it forms and functions. On one hand, party identification can be thought of as a fixed social identity; on the other, it can be seen as a more mutable, policy-based commitment. Our study is an attempt to differentiate between these two possibilities observationally.

In research focused on party identification as a social identity, it has been viewed as an affective affiliation determined early in life based on one’s social environment (Campbell et al., 1960; Berelson et al., 1986). In this view, party identification is relatively stable long-term, with voters basing their affiliations on their stereotypes or mental models of the kinds of people that constitute each party and their conceptions of themselves (Green et al., 2002). Empirically, this theory is supported by evidence that people's responses to political information are biased by their party identification, suggesting that party identification drives opinion, rather than opinion driving to party identification (Bartels, 2002; Huddy et al., 2015). 

However, other work suggests that policy preferences do play a role in generating party identification. This school of thought sees party identification as a label that people update based on how each party is performing in terms of meeting their interests (Fiorina, 1981). As elites become increasingly sorted on policy views, it is easier for people to understand where the parties stand on given issues (Levendusky, 2010; Webster and Abramowitz, 2017). This makes social cues about party more meaningful in terms of policy preferences; people may follow elites because they feel they share political interests (Bullock, 2011). That voters tend to interpret belonging to the other party as holding views they disagree with supports this theory, suggesting there is not such a chasm between party as social identity and party as expression of policy preferences as was once thought (Orr & Huber, 2020; Fowler, 2020). 

Nonetheless, the debate is far from resolved. The effects of social identities and policy preferences are difficult to distinguish, especially experimentally. Knowing policy preferences makes it easy for people to infer party identification (Goggin et al., 2019) and vice versa (Milita et al., 2019; Rothschild et al., 2019). The difference between predictors of *levels* of party identification at a single time point and predictors of *change* in party identification also remains insufficiently explored. Furthermore, existing research has not distinguished short-lived, erratic fluctuations in party identification from systematic, linear changes in party identification over time. Yet these short-term fluctuations may obscure how party identification changes and what drives that change.

# Methods
## Data
We use the Institute for the Study of Citizens and Politics (ISCAP) panel for all analyses. The fifteen-wave panel has been administered by Knowledge Networks/GfK since October 2007, with the last wave being completed in October 2020. Thus, the panel spans 13 years and the entire presidential administrations of Barack Obama and Donald Trump. 

ISCAP panelists were drawn from the 2008 National Annenberg Election Study (NAES), which recruited around 20,000 participants via random-digit dialing or address-based sampling. In 2012, a quota-matched sample of approximately 2,500 NAES participants was re-interviewed. These constitute the ISCAP panelists. Quota-matching was managed such that ISCAP panelists would be representative of US adults. However, in reality, participants who are White, college-educated, and over 45-years-old are somewhat underrepresented. The first five waves of data in the ISCAP panel were pulled from the 2008 NAES.

Our final sample includes observations from 2,471 panelists across 15 waves, totaling 34,594 observations. Time between waves is captured by the number of years that had passed since the field date of the panel’s first wave, October 2, 2007. This is essential to account for the uneven distribution of waves across the thirteen-year panel period.

```{r load data, include = F, echo = F, message = F, warning = F}
# Load data
change_data <- import('closedEnds_data/clean_data/change_data.RData')
trait_data <- import('closedEnds_data/clean_data/traits_data.RData')

# Lengthen change data and merge with traits data
merged_data <- change_data %>% 
  pivot_longer(cols = -MNO,
               names_to = c('.value', 'wave'),
               names_sep = '_') %>%
  left_join(trait_data, by = 'MNO')
```

## Item Selection
The ISCAP panel includes many questions ideal for testing the nature of party identification, particularly its social-identity versus political roots. To begin, the panel includes a seven-point measure of party identification, which captures both which party the respondent identifies with (if any) and the extent to which a respondent identifies with the party. Based on the American National Election Study’s three-question, branching measure of party identification, this measure allows us to capture slight movement in party identification, say, from “weak” Republican to “strong” Republican.

Additionally, the ISCAP panel includes several items that allow us to capture social drivers of party identification, such as respondent demographics, measures of prejudice toward Black people and Hispanics, and indexes for “fear of favoritism” toward Black people and women. As for political or policy-based sources of party identification, the panel includes questions on respondents' attitudes toward tax, immigration, trade, and health care policy, among other issues. 

Notably, some of these variables are stable over time (e.g., race) whereas others are time-variant. To combine these variables into a single analysis, while also isolating within-individual change in our time-variant variables, we utilize a two-stage OLS regression approach. We isolate within-individual change based on our interest in what drives changes in party identification, and to minimize the potential for confounding relationships with time-invariant variables (Vaisey & Miles, 2014). In accordance with standard practice for growth models, we only use time-variant variables for which we have five measurements per respondent (Grimm et al., 2016). In the end, we identified a total of 21 variables for analysis. Further details on how the original data was processed prior to the analyses herein are included in the attached replication materials.

# Exploratory Analysis
## Movement on Party Identification
Before creating a model to predict within-individual change in party identification, we first looked at the variation in party identification in this sample. The alluvial diagram below helps illuminate movement on party identification (numbered 1 to 7, with 1 representing 'Strong Democrat' and 7 representing 'Strong Republican') across panel waves. In this figure, it is clear that people did change their party identification throughout the panel. Though scholars have often reduced party identification to three categories - Democrat, Independent, and Republican - we can see considerable movement within these broad categories. This indicates that even if a person's party identification did not shift, its strength could have. For that reason, we kept our measure of party identification at this level of granularity.

```{r party ID alluvial plot, echo = F, message = F, warning = F}
change_data$partyid <- as.factor(change_data$PID7)

ggplot(data = subset(change_data, !is.na(partyid)),
       aes(x = years, 
           stratum = partyid, 
           alluvium = MNO,
                      fill = partyid, label = partyid)) +
  scale_x_discrete(expand = c(.1, .1)) +
  geom_flow() +
  geom_stratum(alpha = .5) +
  geom_text(stat = 'stratum', size = 3) +
  xlab('Years since October 2, 2007') + 
  theme(legend.position = 'none') +
  ggtitle('Change in Party Identification from 2007 to 2020')
```

## Demographics
It is also helpful to explore variation on some independent variables that may drive within-individual changes in party identification. Based on prior work supporting the 'social identity' theory of party identification, we anticipate that key demographic identities may play a role.

For example, age is often explored as a factor in explaining the development of party identification (e.g., Margolis, 2018). The distributions of our respondents in the first panel wave and the last are represented below. Respondents ranged in age from 18 to over 75 and are distributed roughly normally around a mean that falls in the fourth age group, ranging from 45-54.

```{r demographic visualizations - age, echo = F, message = F, warning = F}
merged_data$party[merged_data$PID7==1] <- 0
merged_data$party[merged_data$PID7==2] <- 0
merged_data$party[merged_data$PID7==3] <- 0
merged_data$party[merged_data$PID7==5] <- 1
merged_data$party[merged_data$PID7==6] <- 1
merged_data$party[merged_data$PID7==7] <- 1
merged_data$party <- factor(merged_data$party, c(0,1), 
                       labels = c("Democrat", "Republican"))

merged_data$twowaves[merged_data$years==0] <- 2007
merged_data$twowaves[merged_data$years>13] <- 2020

# AGE
age <- ggplot(data=subset(merged_data, !is.na(party) & twowaves==2007|
                            !is.na(party) & twowaves==2020), 
            aes(AGE, fill = party)) +
  labs(y = 'Proportion', 
       title = 'Distribution of Panelist Age',
       fill = "Party") + 
  scale_fill_manual(values = c("blue", "red")) +
    scale_x_discrete(name = 'Age',
                     limits = c('18-24', '25-34', '35-44',
                             '45-54', '55-64', '65-74', '75+')) +
  theme(legend.position="bottom") + 
  facet_grid(~ twowaves) + 
  geom_bar(position="fill")

age
```

Likewise, exit polls in recent elections have shown a widening so-called 'diploma
divide' between the parties (Arnade, 2020), so we might expect level of education
to play a role in changes in party identification. Most of our respondents have 
at least a high school education, and nearly half have either some college education,but variation in this variable should let us identify if it could potentially be driving within-individual change in party identification, in addition to being so strongly correlated with vote choice.

```{r demographic visualizations - edu, echo = F, message=F, warning=F}
# EDU
edu <- ggplot(data=subset(merged_data, !is.na(party) & twowaves==2007|
                            !is.na(party) & twowaves==2020), 
            aes(EDU, fill = party)) +
  labs(y = 'Proportion', 
       title = 'Distribution of Panelist Education',
       fill = "Party") + 
  scale_fill_manual(values = c("blue", "red")) +
    scale_x_discrete(name = 'Education',
                     limits = c('Less \nthan HS', 'HS', 'Some \nCollege',
                             'BA or \nHigher')) +
  theme(legend.position="bottom") + 
  facet_wrap(~ twowaves) + 
  geom_bar(position="fill")

edu
```

Finally, we know that race is also correlated with party identification. Could it
also explain shifts in party identification? In this panel, the vast majority of 
respondents are white. We will examine race as a factor, but based on the figure 
below, this may not be the ideal dataset for understanding the role it plays, 
given the relatively limited variation in our sample.

```{r demographic visualizations - race, echo = F, message = F, warning = F}
# RACE
race <- ggplot(data=subset(merged_data, !is.na(party) & twowaves==2007|
                            !is.na(party) & twowaves==2020), 
            aes(RACE, fill = party)) +
  labs(y = 'Proportion', 
       title = 'Distribution of Panelist Race',
       fill = "Party") + 
  scale_fill_manual(values = c("blue", "red")) +
    scale_x_discrete(name = 'Race/Ethnicity',
                     labels = c('2+ Races\nNon-Hispanic',
                              'Black\nNon-Hispanic',
                              'Hispanic',
                              'Other\nNon-Hispanic',
                              'White\nNon-Hispanic')) +
  theme(legend.position="bottom") + 
  facet_wrap(~ twowaves) + 
  geom_bar(position="fill") +
  theme(axis.text.x=element_text(size=rel(0.5)))

race
```

## Policy Opinions
The alternative to the 'social identity' theory of party identification, the "running tally" view, places a greater emphasis on policy opinions, assuming that people continuously update their ideas of each party based on how they perform with respect to their policy preferences. To test this theory, we also need variation on key policy opinions over time, in order to determine if changes in some opinions are related to changes in party identification.

We can use similar alluvial plots to that we used to examine changes in party identification to explore shifts in policy opinions. For example, the diagram below shows changes in support for the Affordable Care Act, with higher values representing more conservative positions on the issue. We see a lot of movement on this issue, with support growing more balanced over the course of the panel.

```{r policy visualization - ACA, echo = F, message = F, warning = F}
ggplot(data = subset(change_data, !is.na(ACA)),
       aes(x = years, 
           stratum = ACA, 
           alluvium = MNO,
                      fill = ACA, label = ACA)) +
  scale_x_discrete(expand = c(.1, .1)) +
  geom_flow() +
  geom_stratum(alpha = .5) +
  geom_text(stat = 'stratum', size = 3) +
  xlab('Years since October 2, 2007') + 
  theme(legend.position = 'none') +
  ggtitle('Change in Positions on the ACA from 2007 to 2020')
```

Likewise, there is plenty of movement on perceptions of individuals' personal economic well-being over the course of the panel. As a core area of dispute between the parties, this seems like a potentially key driver of movement between them, if people are updating their party identification based on a "running tally" that includes economic perceptions. 

```{r policy visualization - PERECO, echo = F, message = F, warning = F}
ggplot(data = subset(change_data, !is.na(PERECO)),
       aes(x = years, 
           stratum = PERECO, 
           alluvium = MNO,
                      fill = PERECO, label = PERECO)) +
  scale_x_discrete(expand = c(.1, .1)) +
  geom_flow() +
  geom_stratum(alpha = .5) +
  geom_text(stat = 'stratum', size = 3) +
  xlab('Years since October 2, 2007') + 
  theme(legend.position = 'right') +
  ggtitle('Change in Perceptions of the National Economy from 2007 to 2020')
```

# Modeling Change in Party Identification
Our statistical analysis proceeds in three steps. First, we model how each panelist changed over time with regard to each time-variant variable by estimating individual, OLS regressions for each time-variant variable. Second, we merge the intercept and slope estimates extracted from Step 1 with our time-invariant data on traits like race and age to create a final dataset. We then exhaustively estimate every possible OLS regression using some combination of all variables in our final dataset, and identify a final model that minimizes the Bayesian Information Criterion (BIC). Third, we use a bootstrapping approach to reintegrate uncertainty present in the individual regressions at Step 1 and produce more accurate confidence intervals about the estimates in our final model.

## Data Preparation
We began by isolating the time-variant variables in our dataset. Then, for each panelist, we regressed each time-variant variable on our measure of time — years since Wave 1 of the ISCAP panel. For example, the following regression was used to estimate the effect of time on each panelists’ attitudes towards tax policy: $TaxPolicy = \beta_0 + \beta_1*Time_t + \epsilon_t$.

After running these panelist-level regressions, we extracted their coefficients and used the intercept ($\beta_0$) to estimate between-subjects differences in panelists’ baseline values on each variable and the effect of time ($\beta_1$) to estimate each panelists’ linear change over time on the variable. We then merged these data with our time-invariant variables to create a dataset with all of our predictors and wherein each row represented a  single panelist. This approach let us estimate individual trajectories in over-time change in our variables, while discounting erratic fluctuations between adjacent waves. 

```{r individual regressions, include = F, echo = F, message = F, warning = F}
# Reload untouched data
change_data <- rio::import('closedEnds_data/clean_data/change_data.RData')
trait_data <- rio::import('closedEnds_data/clean_data/traits_data.RData')

# Get panelist-level beta coefficients
## Create vectors to iterate over and to store results  
vars <- change_data %>% dplyr::select(-MNO, -years) %>% names()
unique_ids <- unique(change_data$MNO)
indBetas_list <- list()

## Loop to run regressions
for (id in 1:length(unique_ids)) {
  ### Create individual-level dataset
  temp_data <- change_data %>% subset(MNO == unique_ids[id])
  
  ### Count NA values
  notNA_counts <- nrow(temp_data) - colSums(is.na(temp_data))
  
  ### Only run regressions if at least one variable has more than 5 observations
  if (any(notNA_counts >= 5)) {
    row <- c(unique_ids[id])
    
    for (var in vars) {
      ### Only run regression if variable has at least 5 observations
      notNA_count <- nrow(temp_data) - sum(is.na(temp_data[, var]))
      
      if (notNA_count >= 5) {
        ### Regression
        lm_formula <- var %>% paste0(' ~ years') %>% as.formula()
        lm_model <- suppressWarnings(summary(lm(lm_formula, data = temp_data)))
        coefs <- lm_model$coefficients %>% as.data.frame()
        
        output <- c(coefs$Estimate[1], coefs$`Std. Error`[1], coefs$Estimate[2],
                    coefs$`Std. Error`[2])
        
        ### Fill NA values (which indicate no variation) with 0's
        output[is.na(output)] <- 0
        
        ### Store results
        row <- c(row, output)
        
      } else {
        row <- c(row, NA, NA, NA, NA)
      }
    }
    
    indBetas_list[[id]] <- row
  }
}

# Create dataframe from results
indBeta_df <- as.data.frame(do.call(rbind, indBetas_list))

## Rename columns
col_names <- c('MNO')

for (var in vars) {
  col_names <- c(col_names, paste0(var, '_2008'), paste0(var, '_2008Error'), 
                 paste0(var, '_slope'), paste0(var, '_slopeError'))
}

names(indBeta_df) <- col_names

# Merge with traits data
merged_data <- merge(trait_data, indBeta_df, by = 'MNO')
```

## Model Selection
We then performed an exhaustive search whereby every combination of time-variant and time-invariant predictors in our merged, final dataset was regressed on within-individual change in party identification (i.e., $\beta_1$ from the panelist-level regressions where party identification was the dependent variable). Given our interest in the *true* model of how our variables affect change in party identification, we selected the model that minimized the Bayesian Information Criterion (BIC). This process yielded six variables that were especially predictive of within-individual change in party identification:

* Attitudes toward the Affordable Care Act in 2008
* Change in attitudes toward the Affordable Care Act over the panel
* Self-reported ideology in 2008
* Change in self-reported ideology over the panel
* Party identification in 2008
* Change in perceptions of the legitimacy of the United States government

```{r model selection, include = F, echo = F, message = F, warning = F}
# GLASSO to identify best model
best_models <- regsubsets(PID7_slope ~., nvmax = 150, 
                        method = 'exhaustive', 
                        data = merged_data %>% select(-matches('Error')))

# Summarize regsubsets output
model_summary <- summary(best_models)
plot(model_summary$bic, ylab = 'BIC', main = 'Testing Error by Number of Betas')
```

In a linear regression predicting the slope of over-time change in party identification from our panelist-level regressions, all six of the coefficients in our final model were significantly different from zero (p < 0.01). '2008' coefficients indicate panelists' party identification developed differently, depending on how they felt about an issue in 2008. For example, higher values on each policy attitude correspond to more conservative positions on a policy issue. As such, those *opposed* to the ACA in 2008 were more likely to drift toward the Republican Party between 2008 and 2020. 

Significant 'change' coefficients indicate that within-individual *changes* in one variable over time were associated with within-individual *changes* in party identification over time. For example, as the slope of change over time in attitudes toward the ACA increased, so did the slope of change over time in party identification. Specifically, a one-unit increase in the slope of ACA-attitude change was associated with a 0.29 increase in the slope of change in party identification. 

All of the variables in our final model correspond to policy attitudes, changeable political experiences, or starting values of party identification. Policy preferences and other changeable, political perceptions were critical in shaping party identification over the Obama and Trump presidencies. Thus, our analysis provides support for the "running tally" theory of party identification: party identification does in fact change, and it changes in tandem with attitudes toward different political issues. 

``` {r final model, echo = F, message = F, warning = F}
model_min <- which.min(model_summary$bic)

# Grab variables at elbow (8)
vars_L0 <- model_summary$which[model_min, ] %>% as.data.frame()
vars_final <- rownames(vars_L0)[vars_L0[, 1]]

# Run model
lm_model <- lm(PID7_slope ~ ACA_2008 + ACA_slope + IDEO7_2008 + IDEO7_slope + 
                 PID7_2008 + SYSLEG_slope, data = merged_data)

# Print model
stargazer(lm_model, type = 'text', style = 'ajps',
          dep.var.labels = 'Change in Party Identification', 
          covariate.labels = c('ACA Attitudes in 2008', 'Change in ACA Attitudes',
                              'Ideology in 2008', 'Change in Ideology', 
                              'Party Identification in 2008', 
                              'Change in Perceptions of U.S. Government Legitmacy',
                              'Constant'))
```

## Re-Estimating Confidence Intervals
A key weakness of our two-stage OLS regression approach is that it underestimates the uncertainty surrounding the relationships between our variables. This is because the uncertainty surrounding the estimates in the panelist-level regressions is not carried over into our final model. 

The simplest solution to this problem is to estimate a multivariate growth model (Grimm et al., 2016), which would estimate average trajectories in our time-variant variables and individual deviations from those average trajectories (e.g., random slopes) simultaneously. However, this approach is computationally intractable given the number of variables in our model (e.g., multiple random slopes).

As such, we opt for a bootstrap approach whereby we repeatedly construct bootstrapped samples from our final dataset and re-estimate our final model. However, we use the standard errors for the coefficients in our panelist-level regressions to simulate these coefficients' sampling distributions and *sample* from these distributions the estimates we carry forward to our final regression. This allows us to carry forward uncertainty from our panelist-level regressions into our final model, and produce more accurate (i.e., wider) confidence intervals. We performed this procedure on a total of 1,000 bootstrapped samples.

```{r reestimating confidence intervals, include = F, echo = F, message = F, warning = F, eval = F}
# Subset final dataset
merged_data <- merged_data %>% 
  select(MNO, PID7_slope, PID7_slopeError, ACA_2008, ACA_2008Error, ACA_slope, 
         ACA_slopeError, IDEO7_2008, IDEO7_2008Error, IDEO7_slope, 
         IDEO7_slopeError, PID7_2008, PID7_2008Error, SYSLEG_slope, 
         SYSLEG_slopeError)

# Bootstrap final model, incorporating error from panelist-level regressions
## Create vectors to iterate over and to store results  
vars <- change_data %>% select(-MNO, -years) %>% names()
unique_ids <- 1:2471
boot_models <- list()

## Loop to run regressions
for (boot in 1:1000) {
  ### Create bootstrapped sample
  boot_data <- merged_data %>% 
    nest(-MNO) %>% 
    sample_frac(size = 1, replace = T) %>%
    unnest(cols = c(data)) %>%
    mutate(MNO = 1:2471)
  
  ### Add random error to coefficient estimates
  model_data <- boot_data %>%
    rowwise() %>%
    mutate(PID7_slope = rnorm(1, mean = PID7_slope, sd = PID7_slopeError),
           ACA_2008 = rnorm(1, mean = ACA_2008, sd = ACA_2008Error),
           ACA_slope = rnorm(1, mean = ACA_slope, sd = ACA_slopeError),
           IDEO7_2008 = rnorm(1, mean = IDEO7_2008, sd = IDEO7_2008Error),
           IDEO7_slope = rnorm(1, mean = IDEO7_slope, sd = IDEO7_slopeError),
           PID7_2008 = rnorm(1, mean = PID7_2008, sd = PID7_2008Error),
           SYSLEG_slope = rnorm(1, mean = SYSLEG_slope, sd = SYSLEG_slopeError)) %>%
    select(-matches('Error'))
  
  ### Regress
  lm_model <- suppressWarnings(summary(lm(PID7_slope ~ ACA_2008 + ACA_slope + 
                                            IDEO7_2008 + IDEO7_slope + 
                                            PID7_2008 + SYSLEG_slope, 
                                          data = model_data)))
  coefs <- lm_model$coefficients %>% as.data.frame()
  
  boot_models[[boot]] <- coefs$Estimate[-1]
}

# Create dataframe from results
boot_out <- as.data.frame(do.call(rbind, boot_models))
names(boot_out) <- c('ACA_2008', 'ACA_slope', 'IDEO7_2008', 'IDEO7_slope', 
                     'PID7_2008', 'SYSLEG_slope')

# Save boostrap
save(boot_out, file = 'boot_out.RData')
```

Using this approach, we find that none of the bootstrapped 95% confidence 
intervals for the variables in our final model overlap with zero. This confirms 
the results of our original linear model: our coefficients are significantly 
different from zero. However, we also find that the size of some of our 
coefficients shrunk substantially. This is likely because a smaller subset of our
panelists drove up our initial estimates. With bootstrapping, these panelists
were sometimes unsampled, and thus had a smaller effect on the coefficients.

```{r review confidence intervals, echo = F}
# Load bootstrapped data
load(file = 'boot_out.RData')

# Summarize output
boot_out %>%
  skim() %>% 
  as.data.frame() %>%
  select(skim_variable, numeric.mean, numeric.sd) %>% 
  rename(Variable = skim_variable, Estimate = numeric.mean, 
         `Std. Error` = numeric.sd) %>%
  mutate(`Lower CI` = Estimate - 1.96*`Std. Error`,
         `Upper CI` = Estimate + 1.96*`Std. Error`) %>%
  knitr::kable()
```


# Conclusions
In sum, our analysis shows that party identification can change significantly over long periods of time. Moreover, it suggests that policy-based and changeable political factors are the key drivers of within-individual change in party identification. These findings are particularly noteworthy given our approach to  measuring within-individual change in our variables. By focusing on within-individual change, the relationships in our model are less likely to be cofounded by time-invariant variables. Moreover, our focus on linear change allows us to discount erratic fluctuations between adjacent waves and focus on systematic change in our variables. This research provides unique evidence for the "running tally" account of party identification, and demonstrates the utility of empirical approaches to studying party identification.

# References

Arnade, C. (2020, November 14). As the racial gap closes, the Democrat-Republican education gap widens. USA Today. https://www.usatoday.com/story/opinion/2020/11/14/2020-election-exit-polls-race-education-chris-arnade-column/3762615001/

Bartels, L. M. (2000). Partisanship and Voting Behavior, 1952-1996. American Journal of Political Science, 44(1), 35. https://doi.org/10.2307/2669291

Bartels, L. M. (2002). Beyond the Running Tally: Partisan Bias in Political Perceptions. Political Behavior, 24(2), 117–150. https://doi.org/10.1023/a:1021226224601

Berelson, B. R., Lazarsfeld, P. F. & McPhee, W. N. (1986). Voting: A Study of Opinion Formation in a Presidential Campaign. University of Chicago Press.

Bullock, J. G. (2011). Elite influence on public opinion in an informed electorate. American Political Science Review. https://doi.org/10.1017/s0003055411000165

Campbell, A., Converse, P. E., Miller, W. E. & Stokes, D. E. (1960). The American Voter. University of Chicago Press. https://doi.org/10.2307/1419686

Converse, P. E. (1964). The nature of belief systems in mass publics. Critical Review, 18(1–3), 1–74. https://doi.org/10.1080/08913810608443650

Fiorina, M. P. (1981). Retrospective Voting in American National Elections. Yale University Press.

Fowler, A. (2020). Partisan Intoxication or Policy Voting? Quarterly Journal of Political Science, 15(2), 141–179. https://doi.org/10.1561/100.00018027a

Freeder, S., Lenz, G. S. & Turney, S. (2019). The Importance of Knowing “What Goes with What”: Reinterpreting the Evidence on Policy Attitude Stability. The Journal of Politics, 81(1), 274–290. https://doi.org/10.1086/700005

Goggin, S. N., Henderson, J. A. & Theodoridis, A. G. (2020). What Goes with Red and Blue? Mapping Partisan and Ideological Associations in the Minds of Voters. Political Behavior, 42(4), 985–1013. https://doi.org/10.1007/s11109-018-09525-6

Green, D., Palmquist, B. & Schickler, E. (2004). Partisan Hearts and Minds. Yale University Press. https://doi.org/10.12987/9780300132007-008

Grimm, K. J., Ram, N. & Estabrook, R. (n.d.). Growth Modeling: Structural Equation and Multi-Level Modeling Approaches. Guilford Press.

Huddy, L., Mason, L. & Aarøe, L. (2015). Expressive Partisanship: Campaign Involvement, Political Emotion, and Partisan Identity. American Political Science Review, 109(1), 1–17. https://doi.org/10.1017/s0003055414000604

Kinder, D. R. & Kalmoe, N. P. (2017). Neither Liberal nor Conservative: Ideological Innocence in the American Pubic. University of Chicago Press.

Levendusky, M. S. (2010). Clearer Cues, More Consistent Voters: A Benefit of Elite Polarization. Political Behavior, 32(1), 111--131. https://doi.org/10.1007/s11109-009-9094-0

Margolis, M. F. (2018). From Politics to the Pews: How Partisanship and the Political Environment Shape Religious Identity. University of Chicago Press.

Milita, K., Simas, E. N., Ryan, J. B. & Krupnikov, Y. (2017). The effects of ambiguous rhetoric in congressional elections. Electoral Studies, 46, 48–63. https://doi.org/10.1016/j.electstud.2017.01.004

Orr, L. V. & Huber, G. A. (2020). The Policy Basis of Measured Partisan Animosity in the United States. American Journal of Political Science, 64(3), 569–586. https://doi.org/10.1111/ajps.12498

Rothschild, J. E., Howat, A. J., Shafranek, R. M. & Busby, E. C. (2019). Pigeonholing Partisans: Stereotypes of Party Supporters and Partisan Polarization. Political Behavior, 41(2), 423–443. https://doi.org/10.1007/s11109-018-9457-5

Vaisey, S. & Miles, A. (2017). What You Can—and Can’t—Do With Three-Wave Panel Data. Sociological Methods & Research, 46(1), 44–67. https://doi.org/10.1177/0049124114547769

Webster, S. W. & Abramowitz, A. I. (2017). The Ideological Foundations of Affective Polarization in the U.S. Electorate. American Politics Research, 45(4), 621–647. https://doi.org/10.1177/1532673x17703132